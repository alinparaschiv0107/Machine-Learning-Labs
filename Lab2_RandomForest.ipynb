{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cxigVMh10QsL",
        "-YWxF81W1jlU"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CLd24Gc0Qoz"
      },
      "source": [
        "# Învățare Automată\n",
        "# Arbori de decizie. Păduri aleatoare\n",
        "### Autori:\n",
        "* Tudor Berariu - 2016\n",
        "* George Muraru - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxigVMh10QsL"
      },
      "source": [
        "## 1. Scopul laboratorului"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CycSr6E4ltrs"
      },
      "source": [
        "Scopul laboratorului îl reprezintă întelegerea conceptului de arbore de decizie și implementarea unor clasificatori bazați pe acest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YWxF81W1jlU"
      },
      "source": [
        "## 2. Problema de rezolvat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3RQxoc61nrD"
      },
      "source": [
        "Problema de rezolvat ı̂n acest laborator este una de ı̂nvățare supervizată: fiind dat un **set de date X** ce conține exemple descrise printr-un set de **atribute discrete A** și etichetate cu **câte o clasă dintr-o mulțime cunoscută C**, să se construiască un model pentru clasificarea exemplelor noi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxWxuiO_16tZ"
      },
      "source": [
        "## 3. Arbore de decizie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBXFgoNYlxdp"
      },
      "source": [
        "Un arbore de decizie este un clasificator ce aproximează funcții discrete.\n",
        "\n",
        "Într-un arbore de decizie există 2 tipuri de noduri:\n",
        "* *noduri intermediare* - conține un test pentru un atribut și are câte un arc (și implicit un subarbore) pentru fiecare valoare posibiliă a atributului\n",
        "* *noduri frunză* - este etichetat cu o clasă\n",
        "\n",
        "Pentru **a clasifica un obiect nou** se pornește din rădăcina arborelui și din fiecare nod se coboară pe arcul corespunzător valorii atributului pe care o are obiectul dat. Atunci când se ajunge ı̂ntr-un nod frunză, clasa acestuia va reprezenta predicția arborelui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQvktw_WbZpk"
      },
      "source": [
        "## 4. Păduri de arbori aleatori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imU3HcNzl13s"
      },
      "source": [
        "*Pădurile de arbori aleatori* (eng. Random Forest) este un model format din mai mulți arbori de decizie.\n",
        "\n",
        "Se bazează pe 2 hiperparametrii:\n",
        "* Eșantionare aleatoare din setul de date de antrenament\n",
        "* Subseturi aleatoare de atribute considerate la împărțirea pe mai multi subarbori\n",
        "\n",
        "Predicția, utilizând un astfel de model, se bazează pe clasa majoritară oferită de predicțiile indepente ale tuturor arborilor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XnuEfno1n4D"
      },
      "source": [
        "## 5. Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvzJhiWfzm9"
      },
      "source": [
        "### Câteva biblioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2lKg7o7nZxo"
      },
      "source": [
        "from math import log2\n",
        "import csv\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVVLxc0geBix"
      },
      "source": [
        "### Hiperparametrii necesari rulării"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTGgZTdXeHaS"
      },
      "source": [
        "DATASET_NAME = 'Tennis'  #@param ['Chess', 'Car', 'Tennis']\n",
        "\n",
        "# Adâncimea arborilor\n",
        "D = 3 #@param {type: \"slider\", min: 2, max: 10}\n",
        "\n",
        "# Procentul de exemple din setul de date utilizat la construcția arborilor\n",
        "P = 50 #@param {type: \"slider\", min: 1, max: 100}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyJFPSkseHlf"
      },
      "source": [
        "### Funcții ajutătoare pentru descărcarea și lucrul cu setul de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZtaRrKceKKg"
      },
      "source": [
        "class Node:\n",
        "    \"\"\" Representation for a node from the decision tree \"\"\"\n",
        "    def __init__(self, label):\n",
        "        \"\"\"\n",
        "            for non-leafs it is the name of the attribute\n",
        "            for leafs it is the class\n",
        "        \"\"\"\n",
        "        self.label = label\n",
        "        \n",
        "        # Dictionary of (attribute value, nodes)\n",
        "        self.children = {}\n",
        "    \n",
        "    def display(self, string):\n",
        "        print(string + self.label)\n",
        "        string += \"\\t\"\n",
        "        if self.children:\n",
        "            for key, value in self.children.items():\n",
        "                print(string + key)\n",
        "                value.display(string + \"\\t\")\n",
        "\n",
        "\n",
        "def getArchive(dataSetName):\n",
        "    \"\"\" Checks if a specific dataset is present in the local directory, if not,\n",
        "    downloads it.\n",
        "\n",
        "    Args:\n",
        "        dataSetName (str): the dataset name\n",
        "    \"\"\"\n",
        "    dataset_file = \"datasets\" + os.sep + dataSetName.lower()\n",
        "    print(dataset_file)\n",
        "    \n",
        "    from os import path\n",
        "    if not path.isfile(dataset_file):\n",
        "        import urllib\n",
        "        print(\"Downloading...\")\n",
        "        urllib.request.urlretrieve(dataset_url, filename=dataset_file)\n",
        "        assert(path.isfile(dataset_file))\n",
        "        print(\"Got the archive\")\n",
        "    else:\n",
        "        print(f\"{dataset_file} already in the local directory\")\n",
        "\n",
        "\n",
        "def getDataSet(dataSetName):\n",
        "    \"\"\" Reads a dataset\n",
        "\n",
        "    Args:\n",
        "        dataSetName (str): Name for the dataset\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing (classes, attributes, examples):\n",
        "        classes (set): the classes that are found in the dataset\n",
        "        attributes (list of strings): the attributes for the dataset\n",
        "        examples (list of dictionaries): one example contains an entry as\n",
        "            (attribute name, attribute value)\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_file = \"datasets\" + os.sep + dataSetName.lower()\n",
        "\n",
        "    f_in = open(dataset_file, 'r')\n",
        "    csv_reader = csv.reader(f_in, delimiter=\",\")\n",
        "\n",
        "    # Read the header row\n",
        "    row = next(csv_reader)\n",
        "\n",
        "    # The last element represents the class\n",
        "    attributeNames = row[:-1]\n",
        "    \n",
        "    examples = []\n",
        "    classes = set()\n",
        "\n",
        "    for row in csv_reader:\n",
        "        *attributes, label = row\n",
        "        classes.add(label)\n",
        "        example = dict(zip(attributeNames, attributes))\n",
        "        example[\"CLASS\"] = label\n",
        "        examples.append(example)\n",
        "    \n",
        "    f_in.close()\n",
        "    return classes, attributeNames, examples"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVpmhw63j89K"
      },
      "source": [
        "### Descărcare și încarcare set de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8fxQ-xekLty",
        "outputId": "730615b7-e957-4d38-8fc9-fc200916ca94"
      },
      "source": [
        "getArchive(DATASET_NAME)\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "examples\n",
        "attributes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets/tennis\n",
            "datasets/tennis already in the local directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Outlook', 'Temperature', 'Humidity', 'Windy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgYby0WVetLL"
      },
      "source": [
        "## 6. Cerințe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU0xmCIFr-fi"
      },
      "source": [
        "1. [3 pct] Implementați o funcție recursivă *randomTree* care construiește arbori de decizie de adâncime **d** pe baza unui **set de date X** și a unei **mulțimi de atribute A** astfel:\n",
        " * Dac̆a *d = 0*, atunci se construiește un nod frunză cu clasa majoritară din X.\n",
        " * Dacă *d > 0*, atunci se alege aleator un atribut $a_i$ din A și se construiește câte un subarbore pentru fiecare valoare $v_j$ a atributului $a_i$ apelând *randomTree* pentru *d − 1*:\n",
        "$$\n",
        "X_{i/j} = \\{x \\in X|a_{i}(x) = v_k\\}\\\\\n",
        "A_{new} = A \\setminus \\{a_i\\}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p77UawVkEM60",
        "outputId": "15e8ad6b-e409-4a8c-e39b-871efed9c62e"
      },
      "source": [
        "print(attributes)\r\n",
        "print(classes)\r\n",
        "print(examples)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Outlook', 'Temperature', 'Humidity', 'Windy']\n",
            "{'no', 'yes'}\n",
            "[{'Outlook': 'sunny', 'Temperature': 'hot', 'Humidity': 'high', 'Windy': 'false', 'CLASS': 'no'}, {'Outlook': 'sunny', 'Temperature': 'hot', 'Humidity': 'high', 'Windy': 'true', 'CLASS': 'no'}, {'Outlook': 'overcast', 'Temperature': 'hot', 'Humidity': 'high', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'rain', 'Temperature': 'mild', 'Humidity': 'high', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'rain', 'Temperature': 'cool', 'Humidity': 'normal', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'rain', 'Temperature': 'cool', 'Humidity': 'normal', 'Windy': 'true', 'CLASS': 'no'}, {'Outlook': 'overcast', 'Temperature': 'cool', 'Humidity': 'normal', 'Windy': 'true', 'CLASS': 'yes'}, {'Outlook': 'sunny', 'Temperature': 'mild', 'Humidity': 'high', 'Windy': 'false', 'CLASS': 'no'}, {'Outlook': 'sunny', 'Temperature': 'cool', 'Humidity': 'normal', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'rain', 'Temperature': 'mild', 'Humidity': 'normal', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'sunny', 'Temperature': 'mild', 'Humidity': 'normal', 'Windy': 'true', 'CLASS': 'yes'}, {'Outlook': 'overcast', 'Temperature': 'mild', 'Humidity': 'high', 'Windy': 'true', 'CLASS': 'yes'}, {'Outlook': 'overcast', 'Temperature': 'hot', 'Humidity': 'normal', 'Windy': 'false', 'CLASS': 'yes'}, {'Outlook': 'rain', 'Temperature': 'mild', 'Humidity': 'high', 'Windy': 'true', 'CLASS': 'no'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOJjGaBUth4V",
        "outputId": "9c46d823-6290-4390-9bf8-8b4ed1e59891"
      },
      "source": [
        "import random\n",
        "import statistics\n",
        "from copy import deepcopy\n",
        "\n",
        "getArchive(DATASET_NAME)\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "\n",
        "def most_frequent(List): \n",
        "    counter = 0\n",
        "    num = List[0] \n",
        "      \n",
        "    for i in List: \n",
        "        curr_frequency = List.count(i) \n",
        "        if(curr_frequency > counter): \n",
        "            counter = curr_frequency \n",
        "            num = i \n",
        "  \n",
        "    return num \n",
        "\n",
        "def randomTree(d, X, A):\n",
        "   # Cerință 1\n",
        "    if d == 0:\n",
        "       mostFrequentClass = most_frequent(list(x[\"CLASS\"] for x in X))\n",
        "       n = Node(mostFrequentClass)\n",
        "    else:\n",
        "        attribute = random.choice(A)\n",
        "        n = Node(attribute)\n",
        "        A.remove(attribute)\n",
        "\n",
        "        sett = []\n",
        "        for i in range(len(X)):\n",
        "            sett.append(X[i][attribute])\n",
        "        atr_values = set(sett)\n",
        "\n",
        "        for val in atr_values:\n",
        "          if d == 1 : \n",
        "            X_prim = []\n",
        "            for i in range(len(X)):\n",
        "              if val in list(X[i].values()):\n",
        "                X_prim.append(X[i])\n",
        "            n.children[val] = randomTree(d - 1, X_prim, deepcopy(A))\n",
        "          else :\n",
        "            n.children[val] = randomTree(d - 1, X, deepcopy(A))\n",
        "\n",
        "    return n\n",
        "\n",
        "n = randomTree(3, examples, attributes)\n",
        "print(n.display(\"\"))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets/tennis\n",
            "datasets/tennis already in the local directory\n",
            "Windy\n",
            "\tfalse\n",
            "\t\tTemperature\n",
            "\t\t\thot\n",
            "\t\t\t\tOutlook\n",
            "\t\t\t\t\train\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tovercast\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tsunny\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\tmild\n",
            "\t\t\t\tOutlook\n",
            "\t\t\t\t\train\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tovercast\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tsunny\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\tcool\n",
            "\t\t\t\tHumidity\n",
            "\t\t\t\t\thigh\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\t\t\tnormal\n",
            "\t\t\t\t\t\tyes\n",
            "\ttrue\n",
            "\t\tOutlook\n",
            "\t\t\train\n",
            "\t\t\t\tTemperature\n",
            "\t\t\t\t\thot\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\t\t\tmild\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tcool\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\tovercast\n",
            "\t\t\t\tTemperature\n",
            "\t\t\t\t\thot\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\t\t\tmild\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tcool\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\tsunny\n",
            "\t\t\t\tTemperature\n",
            "\t\t\t\t\thot\n",
            "\t\t\t\t\t\tno\n",
            "\t\t\t\t\tmild\n",
            "\t\t\t\t\t\tyes\n",
            "\t\t\t\t\tcool\n",
            "\t\t\t\t\t\tyes\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjYqUPSbe1gG"
      },
      "source": [
        "2. [3 pct] Implementați o funcție recursivă *id3* care construiește arbori de decizie pe baza unui **set de date X** și a unei **mulțimi de atribute A**.\n",
        "    \n",
        "  Trebuie avute în vedere următoarele aspecte:\n",
        "  * dacă toate exemplele din X aparțin unei singure clase C, atunci se construiește un nod frunză etichetat cu acea clasă C\n",
        "  * dacă nu mai exista atribute, atunci construiește nodul frunză etichetat cu cea mai frecventă clasă din X\n",
        "    \n",
        "  În caz contrar:\n",
        "  * se alege atributul $a^*$ care aduce cel mai mai mare câștig informațional și se construiește un *nod intermediar* corespunzător acestuia.\n",
        "\n",
        "  $$\n",
        "    entropy(X) = -\\sum_{c \\in C}\\frac{|X_c|}{|X|}log_2\\frac{|X_c|}{|X|}\n",
        "  $$\n",
        "  $$\n",
        "    gain(X, a) = entropy(X) - \\sum_{v_{j} \\in vals(a)} \\frac{|X_{i/j}|}{|X|}entropy(X_{i/j})\n",
        "  $$\n",
        "  $$\n",
        "    a^* = \\underset{a \\in A}{\\operatorname{arg max}}\\ gain(X, a)\n",
        "  $$\n",
        "\n",
        "  * pentru fiecare valoare posibilă $v_j$ a lui $a^*$ se construiește un subarbore apelând recursiv funcția *id3* pentru:\n",
        "\n",
        "$$\n",
        "  X_j = \\{x \\in X|a^*(x) = v_j\\}\\\\\n",
        "  A_{new} = A\\setminus\\{a^*\\}\n",
        "$$\n",
        "\n",
        "În cazul prezentat mai sus, entropia este utilizată pentru a măsura randomness-ul din date. Intuitiv, cu cât un eveniment are probabilitate mai mare să se întâmple atunci acesta va avea o entropia din ce în ce mai mică. Prin modul în care se construiește arborele *ID3* se încearcă reducerea entropiei alegând la fiecare pas atributele care ne ofera cea mai multă informație. Cât considerați că este entropia într-un *nod frunză*?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3vjt6tKhbcJ"
      },
      "source": [
        "def countElems(X,elem):\r\n",
        "  count = 0\r\n",
        "  vals = list(x[\"CLASS\"] for x in X)\r\n",
        "  for i in vals:\r\n",
        "    if i == elem:\r\n",
        "      count = count + 1\r\n",
        "  \r\n",
        "  return count\r\n",
        "\r\n",
        "def findSubset(X,Att,Value):\r\n",
        "  subset = []\r\n",
        "  for x in X:\r\n",
        "    if x[Att] == Value:\r\n",
        "      subset.append(x) \r\n",
        "  return subset\r\n",
        "\r\n",
        "def findValuesfromAtt(X,Att):\r\n",
        "    values = []\r\n",
        "    for x in X:\r\n",
        "      values.append(x[Att])\r\n",
        "    return set(values)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_vvpBBve0-D",
        "outputId": "12d5410e-9f84-4d56-d525-4d1eaa723e10"
      },
      "source": [
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "\n",
        "def mostFrequentClass(X):\n",
        "    # TODO Cerință 2\n",
        "    return most_frequent(list(x[\"CLASS\"] for x in X))\n",
        "\n",
        "def entropy(X):\n",
        "    # TODO Cerință 2\n",
        "    if countElems(X,'yes') == 0 and not countElems(X,'no') == 0:\n",
        "      return - countElems(X,'no') / len(X) * log2(countElems(X,'no') / len(X))\n",
        "    elif not countElems(X,'yes') == 0 and countElems(X,'no') == 0:\n",
        "      return - countElems(X,'yes') / len(X) * log2(countElems(X,'yes') / len(X))\n",
        "    elif countElems(X,'yes') == 0 and countElems(X,'no') == 0:\n",
        "      return 0\n",
        "    else:\n",
        "      return - (countElems(X,'yes') / len(X) * log2(countElems(X,'yes') / len(X)) + countElems(X,'no') / len(X) * log2(countElems(X,'no') / len(X)))\n",
        "\n",
        "def gain(X, A):\n",
        "    # TODO Cerință 2\n",
        "    att_dict = {}\n",
        "    inf_gain_dict = {}\n",
        "\n",
        "    for a in A:\n",
        "      att_dict[a] = findValuesfromAtt(examples,a)\n",
        "\n",
        "    for a in A:\n",
        "      H_att = 0\n",
        "      for v in att_dict[a]:\n",
        "        subset = findSubset(examples,a,v)\n",
        "        H_val = entropy(subset)\n",
        "        H_att = H_att + len(subset) / len(examples) * H_val\n",
        "      inf_gain_dict[a] = H_att\n",
        "\n",
        "    # print(inf_gain_dict)\n",
        "    max_H = max(list(inf_gain_dict.values()))\n",
        "    max_H_pos = list(inf_gain_dict.values()).index(max_H)\n",
        "\n",
        "    return list(inf_gain_dict.keys())[max_H_pos]\n",
        "\n",
        "def id3(X, A, m ='fail'):\n",
        "    if len(A) == 0:\n",
        "      n = Node(m)\n",
        "      return n\n",
        "    \n",
        "    attribute = gain(X,A)\n",
        "    n = Node(attribute)\n",
        "    A.remove(attribute)\n",
        "\n",
        "    m = mostFrequentClass(X)\n",
        "\n",
        "    for v in findValuesfromAtt(X,attribute):\n",
        "      subset_v = findSubset(X,attribute,v)\n",
        "      n.children[v] = id3(subset_v,deepcopy(A),m)\n",
        "\n",
        "    return n\n",
        "\n",
        "def evaluate(tree, example):\n",
        "    # TODO Cerință 2\n",
        "    # Functia intoarce clasa prezisa de arborele `tree` pentru exemplul `example`\n",
        "    curr_node = tree\n",
        "    ex_attributes = list(example.keys())\n",
        "    ex_attributes.remove('CLASS')\n",
        "\n",
        "    while not len(curr_node.children) == 0:\n",
        "      curr_node = curr_node.children[example[curr_node.label]]\n",
        "    \n",
        "    return curr_node.label\n",
        "\n",
        "def precision(tree, X, c):\n",
        "    prec = 0\n",
        "    predicted_ct = 0\n",
        "    \n",
        "    for ex in X:\n",
        "        pred_c = evaluate(tree, ex)\n",
        "        if pred_c == c:\n",
        "            predicted_ct += 1\n",
        "            if ex['CLASS'] ==c:\n",
        "                prec += 1\n",
        "    \n",
        "    if predicted_ct != 0:\n",
        "        return prec / predicted_ct\n",
        "    return 0\n",
        "\n",
        "def recall(tree, X, c):\n",
        "    X_c = list(filter(lambda ex: ex['CLASS'] == c, X))\n",
        "    recall = 0\n",
        "    \n",
        "    for ex in X_c:\n",
        "        pred_c = evaluate(tree, ex)\n",
        "        if pred_c == c:\n",
        "            recall += 1\n",
        "            \n",
        "    recall /= len(X_c)\n",
        "    return recall\n",
        "\n",
        "def accuracy(tree, X):\n",
        "    count = 0\n",
        "    for x in X:\n",
        "      if evaluate(tree, x) == x['CLASS']:\n",
        "        count += 1\n",
        "        \n",
        "    return 1.0 * count / len(X)\n",
        "\n",
        "\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "tree = randomTree(4, examples, attributes)\n",
        "print('=== RANDOM TREE ===')\n",
        "print('Precision:' ,precision(tree, examples, 'yes'))\n",
        "print('Recall: ', recall(tree, examples, 'yes'))\n",
        "print('Accuracy: ' , accuracy(tree, examples))\n",
        "\n",
        "print()\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "tree = id3(examples,attributes)\n",
        "# print(tree.display(\"\"))\n",
        "print('=== ID3 ===')\n",
        "print('Precision:' ,precision(tree, examples, 'yes'))\n",
        "print('Recall: ', recall(tree, examples, 'yes'))\n",
        "print('Accuracy: ' , accuracy(tree, examples)) "
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== RANDOM TREE ===\n",
            "Precision: 0.6666666666666666\n",
            "Recall:  0.6666666666666666\n",
            "Accuracy:  0.5714285714285714\n",
            "\n",
            "=== ID3 ===\n",
            "Precision: 0.7777777777777778\n",
            "Recall:  0.7777777777777778\n",
            "Accuracy:  0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFh6b_z0vxhk"
      },
      "source": [
        "3. [4 pct] Implementați clasificator de tip pădure de arbori aleatori construind *n* arbori de adâncime maximă *d* fiecare dintre aceștia pornind de la o submulțime aleatoare a lui X.\n",
        "\n",
        "    Folosiți funcția *randomTree* de la cerința 1.\n",
        "  * Porniți de la *n = 100*, *d = 3* și submulțimi formate din 50% din elementele lui X alese la întamplare și experimentați cu acești hiperparametrii.\n",
        "  * Pentru predicția clasei pentru obiecte noi alegeți clasa majoritară\n",
        "  * Comparați rezultatele obținute folosind un singur arbore construit cu ID3 și o pădure de arbori aleatori. Discuție după *zgomot*, *overfitting*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJrnzRr5gJn0"
      },
      "source": [
        "**Nu stiu ce sa fac in cazul in care nu gaseste o valoare pentru atribut. In sampling nu e garantat ca toate valorie se regasesc in tree. :(**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "_LOaeUgIez66",
        "outputId": "69fb7aae-eff4-4ac3-f2b9-d1d0d6ca9232"
      },
      "source": [
        "from statistics import mean \n",
        "\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "\n",
        "def randomForest(X, n, d):\n",
        "    forest = []\n",
        "    \n",
        "    for i in range(n):\n",
        "        sample = random.sample(X, int(len(X) / 2))\n",
        "\n",
        "        A = list(sample[0].keys())\n",
        "        A.remove(\"CLASS\")\n",
        "        forest.append(randomTree(d, sample, A))\n",
        "    \n",
        "    return forest\n",
        "    \n",
        "frst = randomForest(examples, 100, 4)\n",
        "\n",
        "results = []\n",
        "med_prec = []\n",
        "med_recall = []\n",
        "med_accuracy = []\n",
        "\n",
        "for i in range(len(frst)):\n",
        "  results.append(evaluate(frst[i], examples[3]))\n",
        "  med_prec.append(precision(frst[i], examples, 'yes'))\n",
        "  med_recall.append(recall(frst[i], examples, 'yes'))\n",
        "  med_accuracy.append(accuracy(frst[i], examples))\n",
        "\n",
        "print('Result: ', most_frequent(results))\n",
        "print('Med Precision: ', mean(med_prec))\n",
        "print('Med Recall: ', mean(med_recall))\n",
        "print('Med Accuracy: ', mean(med_accuracy))"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-285-e4e09d7dabab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmed_prec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mmed_recall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mmed_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-283-b8a43e80cff3>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(tree, X, c)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mpred_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_c\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpredicted_ct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-283-b8a43e80cff3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(tree, example)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0mcurr_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcurr_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'hot'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzAB53E6HEJN"
      },
      "source": [
        "## 7. Set de date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93rR0yIOflFr"
      },
      "source": [
        "În cadrul acestui laborator se vor folosi seturile de date [Car Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation), [Chess](https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29) și [Tennis](https://www.kaggle.com/fredericobreno/play-tennis).\n",
        "\n",
        "Aceste seturi de date sunt \"ușor\" modificate astfel încât pe prima linie să se afle atributele și labelul/clasa din care face parte fiecare exemplu.\n",
        "\n",
        "Atributele datasetului *Chess* nu sunt intuitive, iar dacă doriți să aflați mai multe informații despre acestea, puteți accesa link-ul de [aici](https://pdfs.semanticscholar.org/db58/88d3f373aff2c6bd7b2f956b81c6896874a9.pdf?_ga=2.193733611.798337455.1582711694-486327444.1582711694)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnH2b3D0kXTd"
      },
      "source": [
        "## 8. Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5JsikeLkZJc"
      },
      "source": [
        "### 8.1 ID3 exemplu\n",
        "Un exemplu mai detaliat pentru construcția arborelui de decizie ID3 se poate găsi [aici](https://github.com/cs-pub-ro/ML/blob/master/lab/lab2/id3_example.pdf).\n",
        "\n",
        "### 8.2 CART\n",
        "Un alt algoritm utilizat poartă denumirea de CART (eng. Classification and Regression Tree). Dacă **ID3** utilizeaza **câștigul informațional (eng. information gain)**, **CART** utilizeaza o altă metrică numită **index-ul Gini (eng. Gini index sau Gini impurity)**.\n",
        "\n",
        "Pentru implementare, se urmăresc exact aceeași [pași ca la ID3](#scrollTo=rjYqUPSbe1gG), singura diferentă fiind modul în care se calculează atributul utilizat într-un *nod intermediar*.\n",
        "$$\n",
        "Gini(X, a) = 1 - \\sum_{c \\in C}{p(c | attr(X) = a) ^2}\n",
        "\\\\\n",
        "a^* = \\underset{a \\in A}{\\operatorname{arg min}}\\ Gini(X, a)\n",
        "$$"
      ]
    }
  ]
}